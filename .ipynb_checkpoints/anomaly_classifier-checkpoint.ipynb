{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ff8c74-1569-4b54-b9fd-10e33e6d82a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "The following code is an ML-based classifier. It generates anomaly-related features that can be\n",
    "used to filter out non-threat-related events. Additionally, it can be used for data transformation \n",
    "during inference, whether in stream-based mode or batch processing mode.\n",
    "\n",
    "IsolationForest is an unsupervised learning algorithm primarily used for anomaly detection. \n",
    "It works by isolating observations through recursive partitioning.\n",
    "Anomaly Score:\n",
    "Observations with shorter average path lengths receive higher anomaly scores and are more likely \n",
    "to be considered anomalies.\n",
    "Conversely, observations with longer average path lengths receive lower anomaly scores and are \n",
    "more likely to be considered normal.\n",
    "'''\n",
    "\n",
    "import os\n",
    "import joblib\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score \n",
    "import sys \n",
    "sys.path.append('/Users/henrychang/sys_security_ai')\n",
    "from utility import get_logger, config_file_loc, load_config, set_working_directory\n",
    "\n",
    "# Set up logging configuration\n",
    "logger = get_logger()\n",
    "\n",
    "\n",
    "class AnomalyClassifier:\n",
    "    def __init__(self, input_file, vectorizer_file, trained_model):\n",
    "        \"\"\"\n",
    "        Initializes the AnomalyClassifier with the input file, vectorizer file, and trained model.\n",
    "\n",
    "        Parameters:\n",
    "            input_file (str): Path to the input CSV file.\n",
    "            vectorizer_file (str): Path to save the trained CountVectorizer.\n",
    "            trained_model (str): Path to save the trained Isolation Forest model.\n",
    "        \"\"\"\n",
    "        self.input_file = input_file\n",
    "        self.vectorizer_file = vectorizer_file\n",
    "        self.trained_model = trained_model\n",
    "        self.df = pd.DataFrame()\n",
    "        # It counts the occurrences of each word in the documents and builds a matrix where each row represents \n",
    "        # a document and each column represents a unique word.\n",
    "        self.vectorizer = CountVectorizer()\n",
    "        self.isolation_forest = IsolationForest(n_estimators=100, contamination=0.1)\n",
    "\n",
    "    def load_data(self):\n",
    "        \"\"\"\n",
    "        Loads data from the specified CSV file into a DataFrame (self.df).\n",
    "        \"\"\"\n",
    "        try:\n",
    "            self.df = pd.read_csv(self.input_file)\n",
    "            logger.info(\"Data loaded\")\n",
    "        except FileNotFoundError:\n",
    "            logger.error(f\"Error: File {self.input_file} not found.\")\n",
    "        except pd.errors.EmptyDataError:\n",
    "            logger.error(\"Error: No data in the file.\")\n",
    "        except pd.errors.ParserError:\n",
    "            logger.error(\"Error: Parsing error.\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error during data loading: {e}\")\n",
    "\n",
    "    def preprocess_data(self):\n",
    "        \"\"\"\n",
    "        Fills missing values in numeric, categorical, datetime, and boolean columns with appropriate replacements.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            for col in self.df.columns:\n",
    "                if self.df[col].dtype in ['float64', 'int64']:  # Numeric columns\n",
    "                    self.df[col].fillna(self.df[col].mean())  # Replace with mean (or use median, 0, etc.)\n",
    "                elif self.df[col].dtype == 'object':  # Categorical columns\n",
    "                    self.df[col].fillna(self.df[col].mode()[0])  # Replace with mode (most frequent value)\n",
    "                elif pd.api.types.is_datetime64_any_dtype(self.df[col]):  # Datetime columns\n",
    "                    self.df[col].fillna(self.df[col].min())  # Replace with earliest date (or a default date)\n",
    "                elif self.df[col].dtype == 'bool':  # Boolean columns\n",
    "                    self.df[col].fillna(False)  # Replace with False (or True, or majority value)\n",
    "            logger.info(\"Data preprocessed\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error during preprocessing: {e}\")\n",
    "\n",
    "    def vectorize_data(self):\n",
    "        \"\"\"\n",
    "        Vectorizes text data for anomaly detection and splits it into training and testing sets.\n",
    "\n",
    "        Returns:\n",
    "            tuple: Vectorized training data, vectorized testing data, training index, testing index.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Vectorize text data for anomaly detection\n",
    "            text_data = self.df['log_text']\n",
    "\n",
    "            # Split data into training and testing sets\n",
    "            X_train, X_test = train_test_split(text_data, test_size=0.2, random_state=42)\n",
    "\n",
    "            # Fit and transform the vectorizer on training data, transform testing data\n",
    "            vectorized_train = self.vectorizer.fit_transform(X_train)\n",
    "            vectorized_test = self.vectorizer.transform(X_test)\n",
    "\n",
    "            return vectorized_train, vectorized_test, X_train.index, X_test.index\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error during vectorization: {e}\")\n",
    "\n",
    "    def train_isolation_forest(self, vectorized_train, vectorized_test, train_index, test_index):\n",
    "        \"\"\"\n",
    "        Trains the Isolation Forest model on the vectorized training data.\n",
    "        Predicts anomalies on the testing data and adds predictions to the DataFrame.\n",
    "        Evaluates model accuracy on test data.\n",
    "\n",
    "        Parameters:\n",
    "            vectorized_train (sparse matrix): Vectorized training data.\n",
    "            vectorized_test (sparse matrix): Vectorized testing data.\n",
    "            train_index (Index): Index of training data.\n",
    "            test_index (Index): Index of testing data.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Train isolation forest on the vectorized training data\n",
    "            self.isolation_forest.fit(vectorized_train)\n",
    "            logger.info(\"Isolation Forest model trained.\")\n",
    "\n",
    "            # Predict anomalies on the testing set\n",
    "            # 1: Indicates that the data point is considered \"normal\" or \"inlier\" by the model.\n",
    "            # -1: Indicates that the data point is considered \"anomalous\" or \"outlier\" by the model.\n",
    "            test_predictions = self.isolation_forest.predict(vectorized_test)\n",
    "            # print(test_predictions)\n",
    "\n",
    "            # Add predictions to the DataFrame\n",
    "            self.df.loc[test_index, 'anomaly'] = test_predictions\n",
    "            # Evaluate the model\n",
    "            true_labels = self.df.loc[test_index, 'anomaly_act'].tolist()\n",
    "\n",
    "            accuracy = accuracy_score(test_predictions, true_labels)  # Assuming anomalies are -1\n",
    "            logger.info(f\"Model accuracy on test data: {accuracy}\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error during isolation forest training: {e}\")\n",
    "\n",
    "    def evaluate_performance(self, test_index):\n",
    "        \"\"\"\n",
    "        Evaluates the performance of the Isolation Forest model on the test data.\n",
    "\n",
    "        Parameters:\n",
    "            test_index (Index): Index of the test data.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Compute the confusion matrix\n",
    "            cm = confusion_matrix(self.df.loc[test_index, 'anomaly_act'], self.df.loc[test_index, 'anomaly'])\n",
    "            logger.info(\"Confusion Matrix:\")\n",
    "            logger.info(cm)\n",
    "\n",
    "            # Print a detailed classification report: precision, recall, f1-score, support\n",
    "            report = classification_report(self.df.loc[test_index, 'anomaly_act'], self.df.loc[test_index, 'anomaly'])\n",
    "            logger.info(\"Classification Report:\")\n",
    "            logger.info(report)\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error evaluating performance: {e}\")\n",
    "\n",
    "    def save_isolation_forest_model(self):\n",
    "        \"\"\"\n",
    "        Saves the trained Isolation Forest model and vectorizer to files.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Save the trained vectorizer\n",
    "            joblib.dump(self.vectorizer, self.vectorizer_file)\n",
    "            logger.info(\"Vectorizer saved\")\n",
    "\n",
    "            # Save the trained isolation forest model\n",
    "            joblib.dump(self.isolation_forest, self.trained_model)\n",
    "            logger.info(\"Isolation Forest model saved\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error saving Isolation Forest model: {e}\")\n",
    "\n",
    "    def run(self):\n",
    "        \"\"\"\n",
    "        Orchestrates the entire workflow by calling the methods in sequence.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            self.load_data()\n",
    "            self.preprocess_data()\n",
    "            vectorized_train, vectorized_test, train_index, test_index = self.vectorize_data()\n",
    "            self.train_isolation_forest(vectorized_train, vectorized_test, train_index, test_index)\n",
    "            self.evaluate_performance(test_index)\n",
    "            self.save_isolation_forest_model()\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error in run process: {e}\")\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        # Load configuration\n",
    "        # config_file_loc = '/Users/henrychang/sys_two_ai/config/config.json'\n",
    "        config = load_config(config_file_loc)\n",
    "        \n",
    "        if config:\n",
    "            # Set desired_directory as working_directory\n",
    "            desired_directory = config.get('desired_directory')\n",
    "            working_directory = set_working_directory(desired_directory)\n",
    "            \n",
    "            if working_directory:\n",
    "                # Get input directory of files\n",
    "                input_dir = config.get('input_dir')\n",
    "                input_data_path = os.path.join(working_directory, input_dir)\n",
    "\n",
    "                # Get path of input data for data_4_modeling\n",
    "                data_4_modeling_file = config.get('data_4_modeling')\n",
    "                data_4_modeling_file_path = os.path.join(input_data_path, data_4_modeling_file)\n",
    "\n",
    "                # Get output directory of files\n",
    "                output_dir = config.get('output_dir')\n",
    "                processed_result_path = os.path.join(working_directory, output_dir)\n",
    "\n",
    "                # Get path of output vectorizer pickle file\n",
    "                vectorizer_file = config.get('vectorizer')\n",
    "                vectorizer_file_path = os.path.join(processed_result_path, vectorizer_file)\n",
    "\n",
    "                #  Get path of output vectorizer pickle file\n",
    "                isolation_forest_model_file = config.get('isolation_forest_model')\n",
    "                isolation_forest_model_file_path = os.path.join(processed_result_path, isolation_forest_model_file)\n",
    "                \n",
    "                detector = AnomalyClassifier(data_4_modeling_file_path, \n",
    "                                 vectorizer_file_path, \n",
    "                                 isolation_forest_model_file_path)\n",
    "                detector.run()\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Unexpected error in main execution: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c569d4f6-e46a-4eca-b1c2-8d03b1088394",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
