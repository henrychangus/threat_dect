{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75cfaa73-2e94-48dc-abbd-476e267b61a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-18 20:47:46,062 - INFO - Path for configuration file: /Users/henrychang/sys_two_ai/config/config.json\n",
      "2025-01-18 20:47:46,063 - INFO - Configuration file loaded successfully\n",
      "2025-01-18 20:47:46,063 - INFO - Current Working Directory: /Users/henrychang/sys_two_ai\n",
      "2025-01-18 20:47:46,064 - INFO - Using MPS\n",
      "Device set to use mps:0\n",
      "2025-01-18 20:47:47,529 - INFO - Threat detection model initialized\n",
      "2025-01-18 20:47:47,530 - INFO - Data loaded\n",
      "2025-01-18 20:47:47,531 - INFO - Data preprocessed\n",
      "2025-01-18 20:47:47,532 - INFO - Simple filtering applied\n",
      "2025-01-18 20:47:47,532 - INFO - Filtered to likely anomalies only\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "2025-01-18 20:48:58,929 - INFO - Threats detected using generative AI\n",
      "2025-01-18 20:48:58,932 - INFO - Results saved to /Users/henrychang/sys_two_ai/output/detection_results.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from transformers import pipeline\n",
    "import os\n",
    "import sys \n",
    "sys.path.append('/Users/henrychang/sys_two_ai')\n",
    "from utility import get_logger, config_file_loc, load_config, set_working_directory, check_and_set_device\n",
    "\n",
    "# Set up logging configuration\n",
    "import logging\n",
    "logger = get_logger()\n",
    "\n",
    "class CybersecurityDetector:\n",
    "    def __init__(self, input_file, output_file):\n",
    "        \"\"\"\n",
    "        Initializes the CybersecurityDetector with input and output file paths.\n",
    "\n",
    "        Parameters:\n",
    "            input_file (str): Path to the input CSV file.\n",
    "            output_file (str): Path to save the output CSV file.\n",
    "        \"\"\"\n",
    "        self.input_file = input_file\n",
    "        self.output_file = output_file\n",
    "        self.df = pd.DataFrame()\n",
    "        try:\n",
    "            # Initialize the threat detection model\n",
    "            device = check_and_set_device()\n",
    "            self.threat_detection_model = pipeline('text-generation', model='gpt2-large', max_length=50, truncation=True, device=device)\n",
    "            # self.threat_detection_model = pipeline(\"text-generation\", model=\"gpt-4\")\n",
    "            # May use model like 'gpt-3.5-turbo' or 'gpt-4', if it's available locally or supported by transformers pipeline.\n",
    "            logger.info(\"Threat detection model initialized\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error initializing threat detection model: {e}\")\n",
    "\n",
    "    def load_data(self):\n",
    "        \"\"\"\n",
    "        Loads data from the specified CSV file into a DataFrame (self.df).\n",
    "        \"\"\"\n",
    "        try:\n",
    "            self.df = pd.read_csv(self.input_file)\n",
    "            logger.info(\"Data loaded\")\n",
    "        except FileNotFoundError:\n",
    "            logger.error(f\"Error: File {self.input_file} not found.\")\n",
    "        except pd.errors.EmptyDataError:\n",
    "            logger.error(\"Error: No data in the file.\")\n",
    "        except pd.errors.ParserError:\n",
    "            logger.error(\"Error: Parsing error.\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error during data loading: {e}\")\n",
    "\n",
    "    def preprocess_data(self):\n",
    "        \"\"\"\n",
    "        Fills missing values in numeric, categorical, datetime, and boolean columns with appropriate replacements.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            for col in self.df.columns:\n",
    "                if self.df[col].dtype in ['float64', 'int64']:  # Numeric columns\n",
    "                    self.df[col].fillna(self.df[col].mean())  # Replace with mean (or use median, 0, etc.)\n",
    "                elif self.df[col].dtype == 'object':  # Categorical columns\n",
    "                    self.df[col].fillna(self.df[col].mode()[0])  # Replace with mode (most frequent value)\n",
    "                elif pd.api.types.is_datetime64_any_dtype(self.df[col]):  # Datetime columns\n",
    "                    self.df[col].fillna(self.df[col].min())  # Replace with earliest date (or a default date)\n",
    "                elif self.df[col].dtype == 'bool':  # Boolean columns\n",
    "                    self.df[col].fillna(False)  # Replace with False (or True, or majority value)\n",
    "            logger.info(\"Data preprocessed\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error during preprocessing: {e}\")\n",
    "\n",
    "    def simple_filter(self):\n",
    "        \"\"\"\n",
    "        Applies a simple rule-based filter to remove non-threat rows based on certain conditions.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Define conditions to filter out non-threat rows\n",
    "            # Define conditions to filter out non-threat rows \n",
    "            filter_conditions = [ 'login successful', \n",
    "                                 'system update', \n",
    "                                 'user logged in', \n",
    "                                 'user logged out', \n",
    "                                 'system rebooted', \n",
    "                                 'file saved', \n",
    "                                 'file opened', \n",
    "                                 'file closed', \n",
    "                                 'session ended', \n",
    "                                 'session started', \n",
    "                                 'heartbeat message', \n",
    "                                 'backup completed', \n",
    "                                 'scheduled task completed', \n",
    "                                 'configuration updated' ]\n",
    "            self.df = self.df[~self.df['log_text'].str.contains('|'.join(filter_conditions), case=False)]\n",
    "            logger.info(\"Simple filtering applied\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error during simple filtering: {e}\")\n",
    "\n",
    "    def filter_anomalies(self):\n",
    "        \"\"\"\n",
    "        Filters data to include only anomalies based on the anomaly_score column.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            self.df = self.df[self.df['anomaly_score'] < 0.5]\n",
    "            logger.info(\"Filtered to likely anomalies only\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error during anomaly filtering: {e}\")\n",
    "\n",
    "    '''\n",
    "    Please note that all the features already created can be used to prepare a sophisticated prompt for more \n",
    "    accurate threat prediction. The prompt in detect_threats() is only a simple example.\n",
    "    '''\n",
    "    def detect_threats(self):\n",
    "        \"\"\"\n",
    "        Detects threats using a generative AI model by analyzing log entries and their classifications.\n",
    "        \"\"\"\n",
    "        def detect_threat(row):\n",
    "            try:\n",
    "                # Create a prompt for threat detection               \n",
    "                prompt = f\"\"\"Log entry: {row['log_text']}\n",
    "                Sentiment Classification: {row['classification']}\n",
    "                Predictive Anomaly Label: {row['anomaly_label']}\n",
    "                Is this potentially a threat?\"\"\"\n",
    "                generated_text = self.threat_detection_model(prompt, max_length=250, num_return_sequences=1)[0]['generated_text']\n",
    "                return 'Threat' if 'threat' in generated_text.lower() else 'Normal'\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Error during threat detection for row: {row.name} - {e}\")\n",
    "                return 'Error'\n",
    "       \n",
    "        try:\n",
    "            self.df['threat_detection'] = self.df.apply(detect_threat, axis=1)\n",
    "            logger.info(\"Threats detected using generative AI\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error applying threat detection: {e}\")\n",
    "\n",
    "    def save_data(self):\n",
    "        \"\"\"\n",
    "        Saves the DataFrame with threat detection results to the specified output CSV file.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            self.df.to_csv(self.output_file, index=False)\n",
    "            logger.info(f\"Results saved to {self.output_file}\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error saving data: {e}\")\n",
    "\n",
    "    def run(self):\n",
    "        \"\"\"\n",
    "        Orchestrates the entire workflow by calling the methods in sequence.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            self.load_data()\n",
    "            self.preprocess_data()\n",
    "            self.simple_filter()\n",
    "            self.filter_anomalies()\n",
    "            self.detect_threats()\n",
    "            self.save_data()\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error in run process: {e}\")\n",
    "\n",
    "class CustomError(Exception):\n",
    "    \"\"\"\n",
    "    This approach ensures that errors are properly logged and propagated without interfering with the IPython or \n",
    "    Jupyter Notebook environment's error handling mechanisms.\n",
    "    \"\"\"\n",
    "    pass\n",
    "    \n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        # Load configuration\n",
    "        config = load_config(config_file_loc)\n",
    "        \n",
    "        if config:\n",
    "            # Set desired_directory as working_directory\n",
    "            desired_directory = config.get('desired_directory')\n",
    "            working_directory = set_working_directory(desired_directory)\n",
    "\n",
    "            # Get API key\n",
    "            api_key = config.get('api_key')\n",
    "            \n",
    "            if working_directory:\n",
    "                '''\n",
    "                # Get input directory of files\n",
    "                input_dir = config.get('input_dir')\n",
    "                input_data_path = os.path.join(working_directory, input_dir)\n",
    "                '''\n",
    "                # Get output directory of files\n",
    "                output_dir = config.get('output_dir')\n",
    "                output_data_path = os.path.join(working_directory, output_dir)\n",
    "\n",
    "                # Get path of output dictionary for missing_dict\n",
    "                transform_results_file = config.get('transform_results')\n",
    "                transform_results_file_path = os.path.join(output_data_path, transform_results_file)\n",
    "                \n",
    "                # Get path of output dictionary for missing_dict\n",
    "                detection_results_file = config.get('detection_results')\n",
    "                detection_results_file_path = os.path.join(output_data_path, detection_results_file)\n",
    "\n",
    "                detector = CybersecurityDetector(transform_results_file_path, \n",
    "                                     detection_results_file_path)\n",
    "\n",
    "                try:\n",
    "                    detector.run()\n",
    "                except Exception as e:\n",
    "                    logger.error(f\"Error executing run method: {e}\")\n",
    "                    raise CustomError(f\"Error executing run method: {e}\") from e\n",
    "    except FileNotFoundError as fnf_error:\n",
    "        logger.error(f\"Configuration file not found: {fnf_error}\")\n",
    "        raise CustomError(f\"Configuration file not found: {fnf_error}\") from fnf_error\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Unexpected error in main execution: {e}\")\n",
    "        raise CustomError(f\"Unexpected error in main execution: {e}\") from e\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9abc97eb-939d-46cf-9da9-ee8039fd0859",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
